{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example\n\ncccc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = 'imgs/juice.png'\n\nimport pyjuice as juice\nimport torch\nimport torchvision\nimport time\nfrom torch.utils.data import TensorDataset, DataLoader\nimport pyjuice.nodes.distributions as dists\n\n\ndef evaluate(pc, loader):\n    lls_total = 0.0\n    for batch in loader:\n        x = batch[0].to(pc.device)\n        lls = pc(x)\n        lls_total += lls.mean().detach().cpu().numpy().item()\n    \n    lls_total /= len(loader)\n    return lls_total\n\n\ndef mini_batch_em_epoch(num_epochs, pc, optimizer, scheduler, train_loader, test_loader, device):\n    for epoch in range(num_epochs):\n        t0 = time.time()\n        train_ll = 0.0\n        for batch in train_loader:\n            x = batch[0].to(device)\n\n            optimizer.zero_grad()\n\n            lls = pc(x)\n            lls.mean().backward()\n\n            train_ll += lls.mean().detach().cpu().numpy().item()\n\n            optimizer.step()\n            scheduler.step()\n\n        train_ll /= len(train_loader)\n\n        t1 = time.time()\n        test_ll = evaluate(pc, loader=test_loader)\n        t2 = time.time()\n\n        print(f\"[Epoch {epoch}/{num_epochs}][train LL: {train_ll:.2f}; test LL: {test_ll:.2f}].....[train forward+backward+step {t1-t0:.2f}; test forward {t2-t1:.2f}] \")\n\n\ndef full_batch_em_epoch(pc, train_loader, test_loader, device):\n    t0 = time.time()\n    train_ll = 0.0\n    for batch in train_loader:\n        x = batch[0].to(device)\n\n        lls = pc(x)\n        lls.mean().backward()\n\n        train_ll += lls.mean().detach().cpu().numpy().item()\n\n    pc.mini_batch_em(step_size = 1.0, pseudocount = 0.1)\n\n    train_ll /= len(train_loader)\n\n    t1 = time.time()\n    test_ll = evaluate(pc, loader=test_loader)\n    t2 = time.time()\n    print(f\"[train LL: {train_ll:.2f}; test LL: {test_ll:.2f}].....[train forward+backward+step {t1-t0:.2f}; test forward {t2-t1:.2f}] \")\n\n\ndef train_mnist_hclt(enable_cudagrph = True):\n\n    device = torch.device(\"cuda:0\")\n\n    train_dataset = torchvision.datasets.MNIST(root = \"./examples/data\", train = True, download = True)\n    test_dataset = torchvision.datasets.MNIST(root = \"./examples/data\", train = False, download = True)\n\n    train_data = train_dataset.data.reshape(60000, 28*28)\n    test_data = test_dataset.data.reshape(10000, 28*28)\n\n    num_features = train_data.size(1)\n\n    train_loader = DataLoader(\n        dataset = TensorDataset(train_data),\n        batch_size = 512,\n        shuffle = True,\n        drop_last = True\n    )\n    test_loader = DataLoader(\n        dataset = TensorDataset(test_data),\n        batch_size = 512,\n        shuffle = False,\n        drop_last = True\n    )\n\n    ns = juice.structures.HCLT(\n        train_data.float().to(device), \n        num_bins = 32, \n        sigma = 0.5 / 32, \n        num_latents = 128, \n        chunk_size = 32\n    )\n    pc = juice.TensorCircuit(ns)\n\n    pc.to(device)\n\n    optimizer = juice.optim.CircuitOptimizer(pc, lr = 0.1, pseudocount = 0.1)\n    scheduler = juice.optim.CircuitScheduler(\n        optimizer, \n        method = \"multi_linear\", \n        lrs = [0.9, 0.1, 0.05], \n        milestone_steps = [0, len(train_loader) * 100, len(train_loader) * 350]\n    )\n\n    if enable_cudagrph:\n        # Dry run to record CUDA graphs\n        for batch in train_loader:\n            x = batch[0].to(device)\n\n            lls = pc(x, record_cudagraph = True)\n            lls.mean().backward()\n            break\n\n    mini_batch_em_epoch(350, pc, optimizer, scheduler, train_loader, test_loader, device)\n    full_batch_em_epoch(pc, train_loader, test_loader, device)\n\n\nif __name__ == \"__main__\":\n    train_mnist_hclt()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}