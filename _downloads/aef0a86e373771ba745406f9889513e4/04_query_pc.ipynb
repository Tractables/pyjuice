{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Query a PC\n\nAssume we have constructed and trained a PC following the previous tutorials. This tutorial demonstrates how to query the PC, i.e., ask probabilistic queries about the distribution encoded by the PC.\n\nWe will cover how to compute marginal and conditional probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_path = 'imgs/juice.png'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate a PC\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a simple PC consisting of two variables $X_1$ and $X_2$:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport pyjuice as juice\nimport pyjuice.nodes.distributions as dists\n\nni0 = juice.inputs(0, num_nodes = 2, dist = dists.Categorical(num_cats = 2))\nni1 = juice.inputs(1, num_nodes = 2, dist = dists.Categorical(num_cats = 4))\n\nms = juice.multiply(ni0, ni1)\nns = juice.summate(ms, num_nodes = 1)\n\nns.init_parameters()\n\npc = juice.compile(ns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move the PC to a GPU:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\npc.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute marginal probabilities\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assume we want to compute the probabilities $P(X_1 = 0)$ and $P(X_1 = 1)$. We need to create two tensors: a \"data\" tensor consisting the values of the observed variables ($X_1$ in this case) and another \"mask\" tensor indicating which variables are missing.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = torch.tensor([[0, 0], [1, 0]]).to(device)\nmissing_mask = torch.tensor([[False, True], [False, True]]).to(device) # True for variables to be conditioned on/are missing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the data tensor, entries corresponding missing variables will be dismissed by PyJuice and will not influence the output.\nThe `missing_mask` can have have shape [batch_size, num_vars] or [num_vars] if for all samples we marginalize out the same subset of variables.\n\nWe proceed to compute the marginal probabilities using :code:`pyjuice.queries.marginal`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lls = juice.queries.marginal(\n    pc, data = data, missing_mask = missing_mask\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For PCs defined on categorical variables, we can alternatively query for marginal probabilities given *soft* evidence, e.g., $P(X_1 = 0 ~\\text{w.p.}~ 0.3 ~\\text{and}~ 1 ~\\text{w.p.}~ 0.7)$.\nThis can be done by defining `date` as a 3D tensor of size [batch_size, num_vars, num_cats]:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = torch.tensor([[[0.4, 0.6, 0, 0], [0, 0, 0, 0]], [[0.3, 0.7, 0, 0], [0, 0, 0, 0]]]).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since $X_1$ has two categories and $X_2$ has four categories, the size of the last dimension of `data` should be 4.\n\nThe soft marginal probabilities can be similarly computed by:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lls = juice.queries.marginal(\n    pc, data = data, missing_mask = missing_mask\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute conditional probabilities\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since every conditional probability can be represented as the quotient of two marginal probabilities, one may wonder why do we need a separate function for computing conditional probabilities.\nIn fact, with :code:`pyjuice.queries.conditional`, we can simultaneously compute a *set of* conditional probabilities. Specifically, given evidence $\\mathbf{E} = \\mathbf{e}$, we can compute $\\forall X \\not\\in \\mathbf{E}, x \\in \\mathrm{val}(X), P(X = x | \\mathbf{e})$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Say we want to compute the conditional probability of $X_2$ given evidence $X_1 = 0$ and $X_1 = 1$, respectively. We prepare the data and the mask similarly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = torch.tensor([[0, 0], [1, 0]]).to(device)\nmissing_mask = torch.tensor([[False, True], [False, True]]).to(device) # True for variables to be conditioned on/are missing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The conditional probabilities are computed as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputs = juice.queries.conditional(\n    pc, data = data, missing_mask = missing_mask, target_vars = [1]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The parameter `target_vars` is used to indicate the subset of variables which we want to compute their conditional probabilities. Probabilities of all variables will be returned if we do not specify `target_vars`.\n\nThe shape of $\\mathrm{outputs}$ is [B, num_target_vars, num_categories]. For example, $\\mathrm{outputs}[1,0,3]$ is the conditional probability $P(X_2 = 3 | X_1 = 1)$.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar to the marginal query, for categorical data, we can also feed *soft* evidence:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = torch.tensor([[[0.4, 0.6, 0, 0], [0, 0, 0, 0]], [[0.3, 0.7, 0, 0], [0, 0, 0, 0]]]).to(device)\nmissing_mask = torch.tensor([[False, True], [False, True]]).to(device)\n\noutputs = juice.queries.conditional(\n    pc, data = data, missing_mask = missing_mask, target_vars = [1]\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}