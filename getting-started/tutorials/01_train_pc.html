

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Train a PC &mdash; PyJuice 2.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=b21de401"></script>
      <script src="../../_static/doctools.js?v=9a2dae69"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Construct Simple PCs" href="02_construct_simple_pc.html" />
    <link rel="prev" title="Tutorials" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            PyJuice
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Train a PC</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#load-the-mnist-dataset">Load the MNIST Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-the-pc">Create the PC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#train-the-pc">Train the PC</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="02_construct_simple_pc.html">Construct Simple PCs</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_construct_hmm.html">Construct an HMM</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_query_pc.html">Query a PC</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_common_transformations.html">PC Structural Transformation Functions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../python-api/pyjuice.html">pyjuice</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python-api/nodes.html">pyjuice.nodes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python-api/tensorcircuit.html">pyjuice.TensorCircuit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../python-api/structures.html">pyjuice.structures</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PyJuice</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Train a PC</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/getting-started/tutorials/01_train_pc.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-getting-started-tutorials-01-train-pc-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code.</p>
</div>
<section class="sphx-glr-example-title" id="train-a-pc">
<span id="sphx-glr-getting-started-tutorials-01-train-pc-py"></span><h1>Train a PC<a class="headerlink" href="#train-a-pc" title="Link to this heading"></a></h1>
<p>This tutorial demonstrates how to create a Hidden Chow-Liu Tree (<a class="reference external" href="https://arxiv.org/pdf/2106.02264.pdf">https://arxiv.org/pdf/2106.02264.pdf</a>) using <code class="code docutils literal notranslate"><span class="pre">pyjuice.structures</span></code> and train the model with mini-batch EM and full-batch EM.
For simplicity, we use the MNIST dataset as an example.</p>
<p>Note that the goal of this tutorial is just to quickly demonstrate the basic training pipeline using PyJuice without covering additional details such as ways to construct a PC, which will be covered in the following tutorials.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># sphinx_gallery_thumbnail_path = &#39;imgs/juice.png&#39;</span>
</pre></div>
</div>
<section id="load-the-mnist-dataset">
<h2>Load the MNIST Dataset<a class="headerlink" href="#load-the-mnist-dataset" title="Link to this heading"></a></h2>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pyjuice</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">juice</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyjuice.nodes.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dists</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span> <span class="o">=</span> <span class="s2">&quot;../data&quot;</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span> <span class="o">=</span> <span class="s2">&quot;../data&quot;</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">download</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">valid_dataset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">drop_last</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">valid_data</span><span class="p">),</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">drop_last</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="create-the-pc">
<h2>Create the PC<a class="headerlink" href="#create-the-pc" title="Link to this heading"></a></h2>
<p>Let’s create a HCLT PC with latent size 128.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span><span class="p">)</span>

<span class="c1"># The data is required to construct the backbone Chow-Liu Tree structure for the HCLT</span>
<span class="n">ns</span> <span class="o">=</span> <span class="n">juice</span><span class="o">.</span><span class="n">structures</span><span class="o">.</span><span class="n">HCLT</span><span class="p">(</span>
    <span class="n">train_data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="n">num_latents</span> <span class="o">=</span> <span class="mi">128</span>
<span class="p">)</span>
</pre></div>
</div>
<p><code class="code docutils literal notranslate"><span class="pre">ns</span></code> is a Directed Acyclic Graph (DAG) representation of the PC.
Specifically, we use <code class="code docutils literal notranslate"><span class="pre">pyjuice.nodes.InputNodes</span></code>, <code class="code docutils literal notranslate"><span class="pre">pyjuice.nodes.ProdNodes</span></code>, and <code class="code docutils literal notranslate"><span class="pre">pyjuice.nodes.SumNodes</span></code> to define vectors of input nodes, product nodes, and sum nodes, respectively.
By also storing the topological structure of the node vectors (with pointers to the child node vectors), we create the PC as a DAG-based structure. <code class="code docutils literal notranslate"><span class="pre">ns</span></code> is also just a node vector defining the root node of the PC.</p>
<p>While being user-friendly, the DAG-based representation is not amenable to efficient computation.
Therefore, before doing any computation, we need to compile the PC with <code class="code docutils literal notranslate"><span class="pre">pyjuice.compile</span></code>, which creates a compact and equivalent representation of the PC.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">pc</span> <span class="o">=</span> <span class="n">juice</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">ns</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="code docutils literal notranslate"><span class="pre">pc</span></code> is an instance of <code class="code docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>. So we can safely assume it is just a neural network with the variable assignments <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> as input and its log-likelihood <span class="math notranslate nohighlight">\(\log p(\mathbf{x})\)</span> as output.
We proceed to move it to the GPU specified by <code class="code docutils literal notranslate"><span class="pre">device</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">pc</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-the-pc">
<h2>Train the PC<a class="headerlink" href="#train-the-pc" title="Link to this heading"></a></h2>
<p>We start by defining the optimizer and scheduler.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">juice</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">CircuitOptimizer</span><span class="p">(</span><span class="n">pc</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">pseudocount</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;EM&quot;</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">juice</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">CircuitScheduler</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;multi_linear&quot;</span><span class="p">,</span>
    <span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span>
    <span class="n">milestone_steps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">*</span> <span class="mi">350</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Optionally, we can leverage CUDA Graphs to hide the kernel launching overhead by doing a dry run.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">lls</span> <span class="o">=</span> <span class="n">pc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">record_cudagraph</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="k">break</span>
</pre></div>
</div>
<p>We are now ready for the training. Below is an example training loop for mini-batch EM.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">350</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">train_ll</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Similar to PyTorch optimizers zeroling out the gradients, we zero out the parameter flows</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Forward pass</span>
        <span class="n">lls</span> <span class="o">=</span> <span class="n">pc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Backward pass</span>
        <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">train_ll</span> <span class="o">+=</span> <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Perform a mini-batch EM step</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">train_ll</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

    <span class="n">t1</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">test_ll</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">pc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">lls</span> <span class="o">=</span> <span class="n">pc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">test_ll</span> <span class="o">+=</span> <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_ll</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="mi">350</span><span class="si">}</span><span class="s2">][train LL: </span><span class="si">{</span><span class="n">train_ll</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">; val LL: </span><span class="si">{</span><span class="n">test_ll</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">].....[train forward+backward+step </span><span class="si">{</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">; val forward </span><span class="si">{</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">] &quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Similarly, an example training loop for full-batch EM is given as follows.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>

    <span class="c1"># Manually zeroling out the flows</span>
    <span class="n">pc</span><span class="o">.</span><span class="n">init_param_flows</span><span class="p">(</span><span class="n">flows_memory</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="n">train_ll</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># We only run the forward and the backward pass, and accumulate the flows throughout the epoch</span>
        <span class="n">lls</span> <span class="o">=</span> <span class="n">pc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">train_ll</span> <span class="o">+=</span> <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="c1"># Set step size to 1.0 for full-batch EM</span>
    <span class="n">pc</span><span class="o">.</span><span class="n">mini_batch_em</span><span class="p">(</span><span class="n">step_size</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">pseudocount</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>

    <span class="n">train_ll</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>

    <span class="n">t1</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="n">test_ll</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">valid_loader</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">pc</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">lls</span> <span class="o">=</span> <span class="n">pc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">test_ll</span> <span class="o">+=</span> <span class="n">lls</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_ll</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_loader</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/time.html#time.time" title="time.time" class="sphx-glr-backref-module-time sphx-glr-backref-type-py-function"><span class="n">time</span><span class="o">.</span><span class="n">time</span></a><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="mi">1</span><span class="si">}</span><span class="s2">][train LL: </span><span class="si">{</span><span class="n">train_ll</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">; val LL: </span><span class="si">{</span><span class="n">test_ll</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">].....[train forward+backward+step </span><span class="si">{</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">; val forward </span><span class="si">{</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">] &quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-getting-started-tutorials-01-train-pc-py">
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e598bde225aeff7f7f120dd63eb87317/01_train_pc.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">01_train_pc.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ceabde479c39a0dcb17a32f5f14a7139/01_train_pc.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">01_train_pc.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/a398e0b6ad427b76aa1e83a10664efce/01_train_pc.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">01_train_pc.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Tutorials" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="02_construct_simple_pc.html" class="btn btn-neutral float-right" title="Construct Simple PCs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, StarAI.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>